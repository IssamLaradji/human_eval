{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 13 results\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import json \n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# loop over results\n",
    "path = \"results\"\n",
    "result_list = []\n",
    "for filename in os.listdir(path):\n",
    "    fname = os.path.join(path, filename, \"model_a.json\")\n",
    "    feedback_fname = os.path.join(path, filename, \"feedback.json\")\n",
    "\n",
    "    if os.path.exists(feedback_fname):\n",
    "        result = load_json(fname)\n",
    "        feedback = load_json(feedback_fname)\n",
    "        result_dict = {\"model_output\": result, \"feedback\": feedback}\n",
    "        result_list += [result_dict]\n",
    "print(\"loaded\", len(result_list), \"results\")\n",
    "# print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chosen</th>\n",
       "      <th>comment</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>1727288408210748</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>1727288431916123</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>1727288028393847</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>this is good</td>\n",
       "      <td>1727287036551341</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>this</td>\n",
       "      <td>17272870808938208</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>1727288405488781</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes</td>\n",
       "      <td>wonderful situation</td>\n",
       "      <td>1727288436640345</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>17272884016576798</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>1727288385993093</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>17272883829094179</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>no</td>\n",
       "      <td>not logical</td>\n",
       "      <td>17272870525248497</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>1727288421989355</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>1727288379715754</td>\n",
       "      <td>Is the output reasonable based on the instruct...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chosen              comment          timestamp  \\\n",
       "0      no                        1727288408210748   \n",
       "1     yes                        1727288431916123   \n",
       "2     yes                        1727288028393847   \n",
       "3     yes         this is good   1727287036551341   \n",
       "4     yes                 this  17272870808938208   \n",
       "5      no                        1727288405488781   \n",
       "6     yes  wonderful situation   1727288436640345   \n",
       "7      no                       17272884016576798   \n",
       "8     yes                        1727288385993093   \n",
       "9      no                       17272883829094179   \n",
       "10     no          not logical  17272870525248497   \n",
       "11     no                        1727288421989355   \n",
       "12    yes                        1727288379715754   \n",
       "\n",
       "                                             question  \n",
       "0   Is the output reasonable based on the instruct...  \n",
       "1   Is the output reasonable based on the instruct...  \n",
       "2   Is the output reasonable based on the instruct...  \n",
       "3   Is the output reasonable based on the instruct...  \n",
       "4   Is the output reasonable based on the instruct...  \n",
       "5   Is the output reasonable based on the instruct...  \n",
       "6   Is the output reasonable based on the instruct...  \n",
       "7   Is the output reasonable based on the instruct...  \n",
       "8   Is the output reasonable based on the instruct...  \n",
       "9   Is the output reasonable based on the instruct...  \n",
       "10  Is the output reasonable based on the instruct...  \n",
       "11  Is the output reasonable based on the instruct...  \n",
       "12  Is the output reasonable based on the instruct...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([r['feedback'] for r in result_list])\n",
    "# df['chosen'].hist()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 211\n",
      "                                              question         chosen  \\\n",
      "0    Which film did Elisha Henig act in most recent...           both   \n",
      "1    Which home team in the third round of the 2014...           both   \n",
      "2    Was The Disaster Artist or the film that has p...           both   \n",
      "3    The voice artist of the girl mammoth in ice ag...  model1_answer   \n",
      "4    Which home team in the third round of the 2014...           both   \n",
      "..                                                 ...            ...   \n",
      "206  Which British mathematician mentioned in the '...        neither   \n",
      "207  Between Ric Flair and the wrestler who has a j...           both   \n",
      "208  Is Prince of Songkla University or the academy...           both   \n",
      "209  Which of Toru Iwatani's works was released mor...           both   \n",
      "210  Which player with top assists in the FA Premie...           both   \n",
      "\n",
      "                    model1_answer                 model2_answer  \n",
      "0                    Future World                  Future World  \n",
      "1               Tottenham Hotspur             Tottenham Hotspur  \n",
      "2                    Snow Buddies                  Snow Buddies  \n",
      "3                           black                        blonde  \n",
      "4               Tottenham Hotspur             Tottenham Hotspur  \n",
      "..                            ...                           ...  \n",
      "206                 Roger Penrose                 Roger Penrose  \n",
      "207                     Ric Flair                     Ric Flair  \n",
      "208  Prince of Songkla University  Prince of Songkla University  \n",
      "209                      Pac-Land                      Pac-Land  \n",
      "210                    Ryan Giggs                    Ryan Giggs  \n",
      "\n",
      "[211 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_results(path=\"/mnt/home/projects/ai-bites/human_eval/\"):\n",
    "    import glob, os\n",
    "    import json\n",
    "\n",
    "    def load_json(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    # Initialize an empty list to hold the results\n",
    "    all_results = []\n",
    "    data = load_json(f\"{path}static/datasets/fmds.json\")\n",
    "    # Use glob to find all relevant JSON files\n",
    "    feedback_files = glob.glob(f'{path}results/fmds/*/*/feedback.json')\n",
    "    print(f'found {len(feedback_files)}')\n",
    "    # Loop through each feedback file and read corresponding model files\n",
    "    for feedback_file in feedback_files:\n",
    "        # Load feedback\n",
    "        feedback = load_json(feedback_file)\n",
    "\n",
    "        # Find corresponding model_a and model_b files\n",
    "        base_path = feedback_file.rsplit('/', 1)[0]  # Get the base path\n",
    "\n",
    "        model_a_file = os.path.join(base_path, 'model_a.json')\n",
    "        model_b_file = os.path.join(base_path, 'model_b.json')\n",
    "\n",
    "        # Check if model files exist\n",
    "        if os.path.exists(model_a_file) and os.path.exists(model_b_file):\n",
    "            model_a = load_json(model_a_file)\n",
    "            model_b = load_json(model_b_file)\n",
    "\n",
    "            # Assuming 'data' is your list of dictionaries and 'feedback' is the dictionary you're checking against\n",
    "            question_to_find = model_a[\"question\"]\n",
    "\n",
    "            # Find the index of the dictionary in 'data' that has the same question\n",
    "            index = next((i for i, item in enumerate(data) if item['question'] == question_to_find), None)\n",
    "\n",
    "            # index will be the index of the matching dictionary or None if not found\n",
    "            # print(\"Index of matching question:\", index)\n",
    "            assert index is not None\n",
    "\n",
    "            # Add a new key to model_a and model_b based on the match\n",
    "            if model_a[\"answer\"] == data[index][\"model1_answer\"]:\n",
    "                model_a[\"name\"] = \"model1_answer\"\n",
    "            elif model_a[\"answer\"] == data[index][\"model2_answer\"]:\n",
    "                model_a[\"name\"] = \"model2_answer\"\n",
    "            else:\n",
    "                werwer\n",
    "\n",
    "            if model_b[\"answer\"] == data[index][\"model2_answer\"]:\n",
    "                model_b[\"name\"] = \"model2_answer\"\n",
    "            elif model_b[\"answer\"] == data[index][\"model1_answer\"]:\n",
    "                model_b[\"name\"] = \"model1_answer\"\n",
    "            else:\n",
    "                ewrwerw\n",
    "            # print(feedback)\n",
    "\n",
    "            if feedback['chosen'] == 'b':\n",
    "                selected_model_name = model_b[\"name\"]\n",
    "            elif feedback[\"chosen\"] == \"a\":\n",
    "                selected_model_name = model_a[\"name\"]\n",
    "            else:\n",
    "                selected_model_name = feedback[\"chosen\"]\n",
    "            # were\n",
    "            # Create a result dictionary\n",
    "            result_dict = {\n",
    "                \"question\": model_a[\"question\"],\n",
    "                # \"chosen\": feedback[\"chosen\"],\n",
    "                \"chosen\": selected_model_name,\n",
    "                \"model1_answer\": data[index][\"model1_answer\"],\n",
    "                \"model2_answer\": data[index][\"model2_answer\"],\n",
    "            }\n",
    "            all_results.append(result_dict)\n",
    "    return all_results\n",
    "\n",
    "all_results = get_results(path=\"/mnt/home/projects/ai-bites/human_eval/\")\n",
    "# print(\"Loaded\", len(all_results), \"results from feedback and model files.\")\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(all_results)\n",
    "print(df)\n",
    "df.to_csv(\"human_eval_v3.csv\", index=False)\n",
    "\n",
    "# model2_answer_count = sum(1 for result in all_results if result['selected_model_name'] == 'model2_answer')\n",
    "# model1_answer_count = sum(\n",
    "#     1 for result in all_results if result[\"selected_model_name\"] == \"model1_answer\"\n",
    "# )\n",
    "# print(f\"Model 2 Answer was chosen {model2_answer_count} times.\")\n",
    "# print(f\"Model 1 Answer was chosen {model1_answer_count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feedback': {'chosen': 'both',\n",
       "  'comment': '',\n",
       "  'timestamp': '1731456005_9416838',\n",
       "  'question': 'Which Output is Better?\\n\\nTask: \"Multimodal MultiHop Question Answering\"\\n\\n\"Evaluate based on which model has a better Answer. Use the Wikipedia links to look up the answer'},\n",
       " 'model_a': {'question': \"Which film did Elisha Henig act in most recently:  The title with a poster featuring a motorcycle or Grey's Anatomy?\",\n",
       "  'answer': 'Future World',\n",
       "  'wiki_pages': \"- Future World (film): <a href='https://en.wikipedia.org/wiki/Future_World_(film)'>https://en.wikipedia.org/wiki/Future_World_(film)</a><br><br>- Grey's Anatomy: <a href='https://en.wikipedia.org/wiki/Grey's_Anatomy'>https://en.wikipedia.org/wiki/Grey's_Anatomy</a>\"},\n",
       " 'model_b': {'question': \"Which film did Elisha Henig act in most recently:  The title with a poster featuring a motorcycle or Grey's Anatomy?\",\n",
       "  'answer': 'Future World',\n",
       "  'wiki_pages': \"- Future World (film): <a href='https://en.wikipedia.org/wiki/Future_World_(film)'>https://en.wikipedia.org/wiki/Future_World_(film)</a><br><br>- Grey's Anatomy: <a href='https://en.wikipedia.org/wiki/Grey's_Anatomy'>https://en.wikipedia.org/wiki/Grey's_Anatomy</a>\"}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_json(\"/mnt/home/projects/ai-bites/human_eval/static/datasets/fmds.json\")\n",
    "all_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model1_answer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m model_b \u001b[38;5;241m=\u001b[39m load_json(model_b_file)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Add a new key to model_a and model_b based on the match\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_a[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[43mfeedback\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel1_answer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m      8\u001b[0m     model_a[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel1_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model1_answer'"
     ]
    }
   ],
   "source": [
    "# Check if model files exist\n",
    "if os.path.exists(model_a_file) and os.path.exists(model_b_file):\n",
    "    model_a = load_json(model_a_file)\n",
    "    model_b = load_json(model_b_file)\n",
    "\n",
    "    # Add a new key to model_a and model_b based on the match\n",
    "    if model_a[\"answer\"] == feedback[\"model1_answer\"]:\n",
    "        model_a[\"name\"] = \"model1_answer\"\n",
    "    else:\n",
    "        model_a[\"name\"] = \"not_model1_answer\"\n",
    "\n",
    "    if model_b[\"answer\"] == feedback[\"model2_answer\"]:\n",
    "        model_b[\"name\"] = \"model2_answer\"\n",
    "    else:\n",
    "        model_b[\"name\"] = \"not_model2_answer\"\n",
    "\n",
    "    # Create a result dictionary\n",
    "    result_dict = {\"feedback\": feedback, \"model_a\": model_a, \"model_b\": model_b}\n",
    "    all_results.append(result_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
